package com.taoxiha.service.crawl.impl;import java.util.ArrayList;import java.util.List;import java.util.regex.Matcher;import com.taoxiha.base.model.Metadata;import com.taoxiha.common.crawl.crawler.Page;import com.taoxiha.common.crawl.crawler.WebCrawler;import com.taoxiha.common.crawl.parser.HtmlParseData;import com.taoxiha.common.crawl.url.WebURL;import com.taoxiha.common.parser.html.jsoup.Jsoup;import com.taoxiha.common.parser.html.jsoup.nodes.Document;import com.taoxiha.common.parser.html.jsoup.nodes.Element;import com.taoxiha.common.parser.html.jsoup.select.Elements;import com.taoxiha.common.utils.CollectionUtil;import com.taoxiha.common.utils.StringUtils;import com.taoxiha.common.utils.log.CrawlLogUtils;import com.taoxiha.common.utils.log.LogUtils;import com.taoxiha.service.crawl.entity.CrawlParams;import com.taoxiha.service.crawl.entity.CrawlResult;import com.taoxiha.service.crawl.entity.MetaDataValueType;import com.taoxiha.service.crawl.entity.UrlRegFilters;public class WebCrawlCore extends WebCrawler {//implements ICrawlCore {		@Override	public void onStart() {		CrawlParams params = (CrawlParams) myController.getCustomData();		params.setCrawlResult(new CrawlResult());		CrawlParams.setInstance(params);	}		@Override	public void onBeforeExit() {		//记录抓取结果//		params.getCrawlConf();	}	@Override	public void handlePageStatusCode(WebURL webUrl, int statusCode,			String statusDescription) {	}	@Override	public void onContentFetchError(WebURL webUrl) {		// Do nothing by default		// Sub-classed can override this to add their custom functionality	}	@Override	public void onParseError(WebURL webUrl) {		// Do nothing by default		// Sub-classed can override this to add their custom functionality	}	public Object getMyLocalData() {		return CrawlParams.getInstance().getCrawlResult();	}	@Override	public boolean shouldVisit(WebURL url) {		String parentUrl = url.getParentUrl();		String href = url.getURL().toLowerCase();		CrawlParams	params= CrawlParams.getInstance();		final  UrlRegFilters urlRegFilters=params.getUrlRegFilters();		boolean flag = true;		if(StringUtils.isNotBlank(urlRegFilters.getParentUrl()) && StringUtils.isNotBlank(parentUrl)){		Matcher matcher = UrlRegFilters.PARENT_URL_FILTERS.matcher(parentUrl);		flag= matcher.find();		}		if(StringUtils.isNotBlank(urlRegFilters.getAccessUrl()) && StringUtils.isNotBlank(href)){			Matcher matcher = UrlRegFilters.ACCESS_URL_FILTERS.matcher(href) ;			flag=matcher.find() && flag;		}	    LogUtils.debug("flag:"+flag+"  url: "+href);		return flag;	}		@Override	public void visit(Page page) {		WebURL web=page.getWebURL();		String url = web.getURL();		//记录日志	   final CrawlParams params= CrawlParams.getInstance();		CrawlResult result=params.getCrawlResult();		final UrlRegFilters urlRegFilters=params.getUrlRegFilters();		LogUtils.crawlLog(web.logStr(params.getTaskNum(),params.getData().getSourceNum()));		boolean isParserData = false;		if(StringUtils.isNotBlank(urlRegFilters.getDownUrl())){			isParserData=UrlRegFilters.DATADOWN_URL_FILTERS.matcher(url).find();		}       //记录抓取结果		result.pageAdd();		result.setSourceNum(params.getData().getSourceNum());		//解析数据		List<String> list=null;		if(isParserData){			list=parserHtml(params.getMetadatas(),page);			}		//记录日志		if(null !=list && list.size()>0){//		long begin=System.currentTimeMillis();			CrawlLogUtils.saveLog(generateFileName(params)).info(CollectionUtil.listToStr(list));//		long end=System.currentTimeMillis();//		System.out.println("消耗："+(end-begin)+"ms");		 LogUtils.dataLog(CollectionUtil.listToStr(list));//		 System.out.println("dataLog:  "+(System.currentTimeMillis()-end)+"ms");		}		//存储数据	}		private static String generateFileName(CrawlParams params){		return params.getTaskNum().concat("-").concat(params.getData().getSourceNum());	}			private List<String> parserHtml(List<Metadata> metadatas,Page page) 	{		CrawlParams	params= CrawlParams.getInstance();		CrawlResult result=params.getCrawlResult();		List<String> list= new ArrayList<String>();		list.add(params.getTaskNum());		list.add(params.getData().getSourceNum());		list.add(String.valueOf(page.getWebURL().getDocid()));		try {		if (page.getParseData() instanceof HtmlParseData) {			HtmlParseData htmlParseData = (HtmlParseData) page.getParseData();			String text = htmlParseData.getText();			String html = htmlParseData.getHtml();			List<WebURL> links = htmlParseData.getOutgoingUrls();			result.linksAdd(links.size());			result.textSizeAdd(text.getBytes(page.getContentCharset()).length);			result.htmlSizeAdd(html.getBytes(page.getContentCharset()).length);		Document doc = Jsoup.parse(html, page.getContentCharset());		 for(Metadata data:metadatas){		 String value = "";		 Elements el = doc.select(data.getDataPath());		 String dataValue=(null==data.getDataValue())?"":data.getDataValue();		  switch(MetaDataValueType.valueOf(data.getDataAttr())){		  case  text: {				value = el.text();				break;			}			case attr: {				value = el.attr(dataValue);				break;			}			case val: {				value = el.val(dataValue).html();				break;			}			case html: {				value = el.html(dataValue).html();				break;			}			case array:{			    StringBuffer array=new StringBuffer("");				for(Element m:el){					array.append(m).append(",");				}				value=array.toString();				value=value.substring(0, value.length()-1);				break;			}						}		  list.add(value);		 }		}		} catch (Exception e) {			LogUtils.errorLog(e.getMessage(),e);		}		return list;		}}