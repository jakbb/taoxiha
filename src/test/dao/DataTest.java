package test.dao;import java.io.IOException;import java.util.ArrayList;import java.util.List;import java.util.regex.Pattern;import org.junit.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.annotation.DirtiesContext;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.AbstractJUnit4SpringContextTests;import com.taoxiha.base.dao.CrawlConfDao;import com.taoxiha.base.dao.DataSourcePoolDao;import com.taoxiha.base.dao.MetadataDao;import com.taoxiha.base.dao.MetadataModelDao;import com.taoxiha.base.model.DataSourcePool;import com.taoxiha.base.model.Metadata;import com.taoxiha.base.model.MetadataModel;import com.taoxiha.common.utils.CollectionUtil;import com.taoxiha.common.utils.StringUtils;import com.taoxiha.common.utils.date.DateUtils;import com.taoxiha.common.utils.io.FileUtils;import com.taoxiha.common.utils.language.Pinyin4jUtil;import com.taoxiha.common.utils.shell.CommandResult;import com.taoxiha.common.utils.shell.ShellHelper;import com.taoxiha.common.utils.shell.ShellUtils;import com.taoxiha.service.crawl.ICrawlService;import com.taoxiha.service.crawl.entity.CrawlInfoConfig;import com.taoxiha.service.crawl.entity.UrlRegFilters;import com.taoxiha.service.exception.ServiceException;@DirtiesContext@ContextConfiguration(locations = { "/spring/datasource.xml","/spring/resource.xml"})public class DataTest extends AbstractJUnit4SpringContextTests {		@Autowired	private CrawlConfDao confDao;	@Autowired	private MetadataDao metadataDao; 	@Autowired	private DataSourcePoolDao dataSourcePoolDao; 	@Autowired	private ICrawlService crawlService;	@Autowired	private MetadataModelDao metadataModelDao;				@Test	public void getCrawl(){		/*CrawlConf conf=	confDao.getByCrawlConfNum("001");		System.out.println(conf.toString());*/		Metadata data= metadataDao.getByMetadataNum("001");		System.out.println(data.toString());	}		@Test	public void testRexUrl(){		String parentUrl="(http://).*?(smarthome\\.qianjia\\.com\\/Channels\\/smarthome\\/news\\/)\\S*";		String accessUrl="(http://).*?(smarthome\\.qianjia\\.com\\/)(channels\\/smarthome\\/news/|html\\/).*?(.html)$";		String downUrl="(http://).*?(smarthome\\.qianjia\\.com\\/html\\/).*?(.html)$";		UrlRegFilters filters = new UrlRegFilters(parentUrl, accessUrl, downUrl);System.out.println(filters.toJson());			}		@Test	public void getDataSource(){		DataSourcePool pool=dataSourcePoolDao.getBySourceNum("003");		System.out.println(pool.toString());	String url="http://smarthome.qianjia.com/html/2014-01/16_223799.html";//	String filters="{"parentUrl":"[\w\W]*(rank)*$","accessUrl":"[\w\W]*(item\?docid=)*$","downUrl":"[\w\W]*(item\?docid=)*$"}"	String filters=pool.getUrlFilters();		 UrlRegFilters urlRegFilters = UrlRegFilters.parserRegx(filters);// 页面过滤String _url="http://smarthome.qianjia.com/channels/smarthome/news/p1.html";	Pattern PARENT_URL_FILTERS = Pattern.compile(urlRegFilters.getParentUrl());		 Pattern ACCESS_URL_FILTERS = Pattern.compile("(http://).*?(smarthome\\.qianjia\\.com\\/Channels\\/smarthome\\/news\\/)\\S*");	Pattern DATADOWN_URL_FILTERS = Pattern.compile(urlRegFilters.getDownUrl());	System.out.println(ACCESS_URL_FILTERS.matcher(url).matches());	}			@Test	public void startCrawl() throws Exception{		try {//			crawlService.crawlByResourceNum("001","test027");			crawlService.crawlByResourceConfNum("002", "task001");			Thread.sleep(100000000000L);		} catch (ServiceException e) {			// TODO Auto-generated catch block			e.printStackTrace();		}	}				@Test	public void  createTableSql(){				String mataModelNum="002";		MetadataModel model=metadataModelDao.getByMetadataModelNum(mataModelNum);		List<Metadata> list=metadataDao.getByMetadataModelNum(mataModelNum);		 String tableName="log_crawl_".concat(model.getModelName());		String desc=model.getModelDesc();		StringBuffer str = new StringBuffer("CREATE TABLE ");		str.append("`").append(tableName).append("` ( ");		str.append("\n");		str.append("`tasknum` varchar(100) DEFAULT NULL COMMENT '任务编号',").append("\n");		str.append("`sourcenum` varchar(100) DEFAULT NULL COMMENT '资源编号',").append("\n");		str.append("`docid` int(10) DEFAULT NULL COMMENT '文档ID',");		for(Metadata data:list){			str.append("\n");			str.append("`").append(data.getDataKey()).append("`");			if(data.getDataSize()>5000){				str.append(" text ");			}else{			str.append(" varchar(").append(data.getDataSize()).append(")");			}			str.append(" DEFAULT NULL COMMENT '").append(data.getDataField()).append("'").append(",");		}		String sql=str.toString();		sql=sql.substring(0, sql.length()-1).concat("\n");		sql=sql.concat(") ENGINE=InnoDB DEFAULT CHARSET=utf8  COMMENT='").concat(desc).concat("'");		System.out.println(sql);	}			@Test	public void  createTableShell(){				//mysqlInfo		String charset="utf8";		String mataModelNum="002";		MetadataModel model=metadataModelDao.getByMetadataModelNum(mataModelNum);		List<Metadata> list=metadataDao.getByMetadataModelNum(mataModelNum);		 String tableName="log_crawl_".concat(model.getModelName());		String desc=model.getModelDesc();		//检查table是否存在		StringBuffer check = new StringBuffer("tbname='").append(tableName).append("'").append("\n");		check.append("result=`").append(getMysqlCmdFix());		check.append("SHOW TABLES LIKE '%$tbname';");		check.append("\n");		check.append("EOF`");		check.append("\n");		check.append("result=`echo $result|awk '{print $3}'`").append("\n");		check.append(" if [ \"$result\" != \"$tbname\" ]").append("\n")		.append(" then").append("\n");		//创建表命令		StringBuffer str= new StringBuffer(getMysqlCmdFix());		str.append("set names ").append(charset).append(";");		str.append("\n");		str.append("CREATE TABLE ");		str.append(tableName).append("( ");		str.append("\n");		str.append("tasknum varchar(100) DEFAULT NULL COMMENT '任务编号',").append("\n");		str.append("sourcenum varchar(100) DEFAULT NULL COMMENT '资源编号',").append("\n");		str.append("docid int(10) DEFAULT NULL COMMENT '文档ID',");		for(Metadata data:list){			str.append("\n");			str.append(data.getDataKey());			if(data.getDataSize()>5000){				str.append(" text ");			}else{			str.append(" varchar(").append(data.getDataSize()).append(")");			}			str.append(" DEFAULT NULL COMMENT '").append(data.getDataField()).append("'").append(",");		}		String sql=str.toString();		sql=sql.substring(0, sql.length()-1).concat("\n");		sql=sql.concat(") ENGINE=InnoDB DEFAULT CHARSET=utf8  COMMENT='").concat(desc).concat("';");		sql=sql.concat("\n quit \n");		sql=sql.concat("EOF").concat("\n").concat("echo 'success'");						//执行脚本结束		StringBuffer end=new StringBuffer("\n");		end.append("else").append("\n");		end.append("echo '").append("exist the table '");		end.append("\n").append("fi");		String cmd=check.append(sql).append(end).toString();//		System.out.println(cmd);		CommandResult result = null;		try {			result = ShellHelper.exec(cmd);			System.out.println(result.getOutput());		} catch (IOException e) {			// TODO Auto-generated catch block			e.printStackTrace();		} catch (InterruptedException e) {			// TODO Auto-generated catch block			e.printStackTrace();		}	}		public static StringBuffer getMysqlCmdFix(){		//mysqlInfo		String mysqlPath="/Applications/MAMP/Library/bin/mysql";		int port=8889;		String user="root";		String password="zhang";		String host="localhost";		String dbName="taoxiha";		String charset="utf8";		StringBuffer mysqlCmd= new StringBuffer(mysqlPath).append(" -P").append(port).append(" -u").append(user);		if(StringUtils.isNotBlank(host)){			mysqlCmd.append(" -h").append(host);		}		mysqlCmd.append(" -p").append(password).append(" <<EOF \n");		mysqlCmd.append(" use ").append(dbName).append(";\n");		return mysqlCmd;				/* /Applications/MAMP/Library/bin/mysql -P8889 -uroot -pzhang <<EOF		use taoxiha; */	}		@Test	public void loadDataIntoDb() throws Exception{		//拼写shell执行脚本      /* /Applications/MAMP/Library/bin/mysql -P8889 -uroot -pzhang <<EOF		use taoxiha; 		LOAD DATA LOCAL INFILE '/data/crawl/taoxiha/task/20131016/task006-001' INTO TABLE log_crawl_baidu_app FIELDS TERMINATED BY '|';		quit		EOF*/		//后续改为从抓取结果表中获取数据		String dataName="20140116/task001-003";		String tableName="log_crawl_qianjia_news";				String dataPath=CrawlInfoConfig.datapath.concat("/").concat(dataName);		StringBuffer str= new StringBuffer(getMysqlCmdFix());		str.append("LOAD DATA LOCAL INFILE '").append(dataPath).append("'");		str.append("  INTO TABLE ").append(tableName).append("  FIELDS TERMINATED BY '|';");		str.append("\n");		str.append("quit").append("\n");		str.append("EOF").append("\n");		str.append("echo 'success' ");		String cmd=str.toString();//		String cmd="/Applications/MAMP/Library/bin/mysql -P8889 -uroot -pzhang -e 'use taoxiha; LOAD DATA LOCAL INFILE '/data/crawl/taoxiha/task/20131016/task006-001' INTO TABLE log_crawl_baidu_app FIELDS TERMINATED BY '|' '";//		String cmd="echo 'show databases;' | /Applications/MAMP/Library/bin/mysql -P8889 -uroot -p'zhang' ";//		cmd = FileUtils.getFileContent("test/resource/loadData");				CommandResult result=ShellHelper.exec(cmd);//		String result=ShellUtils.execShellCmd(cmd);//	System.out.println(result);	System.out.println(result.getOutput());//	Thread.sleep(1000000L);		}			@Test	public void logSequence(){		List<Metadata> list=metadataDao.getByMetadataModelNum("001");		List<String> strs=new ArrayList<String>();		strs.add("docid");		strs.add("sourcenum");		strs.add("tasknum");		/*TreeMap<String,Object> map=new TreeMap<String,Object>();		map.put("docid","docid");		map.put("sourcenum","sourcenum");		map.put("tasknum", "tasknum");*/		for(Metadata data:list){//			map.put(data.getDataKey(), data.getDataKey());			strs.add(data.getDataKey());		}//		System.out.println(CollectionUtil.mapToStr(map));		System.out.println(CollectionUtil.listToStr(strs));			}			public static void arrayTest(){		String str=FileUtils.getFileContent("test/resource/array");		String[] array=str.split(",");		System.out.println(array[0]);	}		public static void main(String[] args) {//		arrayTest();//		System.out.println(DateUtils.getUnixTime());		String url="http://smarthome.qianjia.com/html/2014-01/16_223799.html";		 Pattern ACCESS_URL_FILTERS = Pattern.compile("(http://).*?(smarthome\\.qianjia\\.com\\/Channels\\/smarthome\\/news\\/p)[0-9]{1,2}.?(html)");			System.out.println(ACCESS_URL_FILTERS.matcher(url).matches());			}			/*  	垂直行业爬虫  抓取网页信息操作步骤		1. 		1）创建元数据模型 	metadata_model表		2）创建数据源编号  data_source_pool表		3）		设置抓取策略 包含网页地址，抓取深度，抓取规则	2. 配置网页过滤条件 父页面 访问页面 下载页面 正则表达式	3. 针对数据爬虫页面 抓取页面元素信息 配置元数据表	4. 设置	  	  	 */		}